{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcc42a44",
   "metadata": {},
   "source": [
    "## Basic config, package loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f308bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set CUDA device\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55bc90b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import sys\n",
    "from omegaconf import OmegaConf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Callable, Tuple\n",
    "from copy import deepcopy\n",
    "import wandb\n",
    "\n",
    "sys.path.append('../')\n",
    "from data_utils import get_eval_data\n",
    "from model.unet import get_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d7b240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load basic config\n",
    "cfg = OmegaConf.load('../configs/conf.yaml')\n",
    "OmegaConf.update(cfg, 'run.iteration', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417b74db",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c201726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msegomezru\u001b[0m (\u001b[33msgomezr\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/repositories/ModelAdapter/src/notebooks/wandb/run-20240422_145202-8y4xbguz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sgomezr/MyProj/runs/8y4xbguz/workspace' target=\"_blank\">dandy-yogurt-8</a></strong> to <a href='https://wandb.ai/sgomezr/MyProj' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sgomezr/MyProj' target=\"_blank\">https://wandb.ai/sgomezr/MyProj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sgomezr/MyProj/runs/8y4xbguz/workspace' target=\"_blank\">https://wandb.ai/sgomezr/MyProj/runs/8y4xbguz/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'debug': False, 'wandb': {'log': True, 'project': 'MyProj'}, 'fs': {'repo_root': '../../', 'root': '../../../../../'}, 'data': {'brain': {'data_path': 'data/conp-dataset/projects/calgary-campinas/CC359/Reconstructed/'}, 'heart': {'acdc': {'data_path': 'data/nnUNet_preprocessed/Task500_ACDC/'}, 'mnm': {'data_path': 'data/nnUNet_preprocessed/Task679_MNM/', 'selection': 'all_cases'}}, 'prostate': {'pmri': {'data_path': 'data/Data/PMRI/'}}}, 'unet': {'weight_dir': '../../pre-trained/trained_UNets/', 'log_dir': '../../pre-trained/trainer_logs/', 'brain': {'pre': 'calgary_unet', 'n_chans_in': 1, 'n_filters_init': 8, 'n_chans_out': 1, 'training': {'train_site': 6, 'augment': True, 'validation': True, 'batch_size': 32, 'num_batches_per_epoch': 250, 'epochs': 250, 'patience': 4, 'lr': 0.001}}, 'heart': {'pre': 'acdc_unet', 'n_chans_in': 1, 'n_filters_init': 8, 'n_chans_out': 4, 'training': {'augment': True, 'validation': True, 'batch_size': 32, 'num_batches_per_epoch': 250, 'num_val_batches_per_epoch': 50, 'epochs': 250, 'patience': 4, 'lr': 0.001}}, 'prostate': {'pre': 'monai-64-4-4', 'n_chans_in': 1, 'n_filters_init': 64, 'n_chans_out': 2, 'training': {'vendor': 'siemens', 'load_only_present': True, 'augment': True, 'validation': True, 'batch_size': 32, 'num_batches_per_epoch': 250, 'num_val_batches_per_epoch': 25, 'epochs': 200, 'patience': 4, 'lr': 0.001}, 'arch': 'monai', 'depth': 4, 'num_res_units': 4}}, 'run': {'iteration': 0, 'data_key': 'prostate'}}\n"
     ]
    }
   ],
   "source": [
    "### Set dataset, either brain, heart or prostate\n",
    "DATA_KEY = 'prostate'\n",
    "OmegaConf.update(cfg, 'run.data_key', DATA_KEY)\n",
    "\n",
    "### get model\n",
    "# available models:\n",
    "#     - default-8\n",
    "#     - default-16\n",
    "#     - monai-8-4-4\n",
    "#     - monai-16-4-4\n",
    "#     - monai-16-4-8\n",
    "#     - monai-32-4-4\n",
    "#     - monai-64-4-4\n",
    "#     - swinunetr\n",
    "\n",
    "unet_name = 'monai-64-4-4'\n",
    "# unet_name = 'swinunetr'\n",
    "args = unet_name.split('-')\n",
    "cfg.unet[DATA_KEY].pre = unet_name\n",
    "cfg.unet[DATA_KEY].arch = args[0]\n",
    "cfg.unet[DATA_KEY].n_filters_init = None if unet_name == 'swinunetr' else int(args[1])\n",
    "if args[0] == 'monai':\n",
    "    cfg.unet[DATA_KEY].depth = int(args[2])\n",
    "    cfg.unet[DATA_KEY].num_res_units = int(args[3])\n",
    "\n",
    "# unet, state_dict = get_unet(\n",
    "#     cfg,\n",
    "#     update_cfg_with_swivels=False,\n",
    "#     return_state_dict=True)\n",
    "# unet.load_state_dict(state_dict)\n",
    "# _ = unet.cuda()\n",
    "\n",
    "wandb.init(\n",
    "    project=cfg.wandb.project,\n",
    "    config={\n",
    "        \"learning_rate\": cfg.unet[DATA_KEY].training.lr,\n",
    "        \"architecture\": unet_name,\n",
    "        \"dataset\": DATA_KEY\n",
    "    }\n",
    ")\n",
    "print(cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405a0bcb",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ad873a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data_utils import get_pmri_data_loaders\n",
    "from trainer.unet_trainer import get_unet_trainer\n",
    "\n",
    "unet = get_unet(cfg, update_cfg_with_swivels=False, return_state_dict=False)\n",
    "train_loader, val_loader = get_pmri_data_loaders(cfg=cfg)\n",
    "pmri_trainer = get_unet_trainer(cfg=cfg, train_loader=train_loader, val_loader=val_loader, model=unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "936d4367",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (32) to match target batch_size (1).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpmri_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/repositories/ModelAdapter/src/notebooks/../trainer/unet_trainer.py:1232\u001b[0m, in \u001b[0;36mUNetTrainerPMRI.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1230\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epochs), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epochs, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m-> 1232\u001b[0m valid_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   1235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/repositories/ModelAdapter/src/notebooks/../trainer/unet_trainer.py:1109\u001b[0m, in \u001b[0;36mUNetTrainerPMRI.eval_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1107\u001b[0m target \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   1108\u001b[0m net_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_step(input_)\n\u001b[0;32m-> 1109\u001b[0m loss_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m   1110\u001b[0m batch_sizes\u001b[38;5;241m.\u001b[39mappend(input_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:1185\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3086\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3085\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (32) to match target batch_size (1)."
     ]
    }
   ],
   "source": [
    "pmri_trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c095178",
   "metadata": {},
   "source": [
    "## Everything Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5255910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set debug mode for only a small fraction of the datasets. Speeds up this cell by alot\n",
    "cfg.debug = True\n",
    "\n",
    "\n",
    "# Wether and how you want to subset in case of Brain data. WARNING:\n",
    "# After subsetting the eval below will not work with surface\n",
    "# Dice anymore, because volumes are fragmented. \n",
    "APPLY_SUBSETTING = True\n",
    "OmegaConf.update(cfg, 'eval.data.subset.apply', APPLY_SUBSETTING)\n",
    "subset_params = {\n",
    "    'n_cases': 256,  # selects at most so many cases\n",
    "    'fraction': 0.1, # selects from the 10% worst cases w.r.t to a model\n",
    "}\n",
    "OmegaConf.update(\n",
    "    cfg, \n",
    "    'eval.data.subset.params', \n",
    "    OmegaConf.create(subset_params)\n",
    ")\n",
    "\n",
    "if cfg.eval.data.subset.apply:\n",
    "    subset_dict = OmegaConf.to_container(\n",
    "        cfg.eval.data.subset.params, \n",
    "        resolve=True, \n",
    "        throw_on_missing=True\n",
    "    )\n",
    "    subset_dict['unet'] = unet\n",
    "else:\n",
    "    subset_dict = None\n",
    "\n",
    "### select the datasets within the domain\n",
    "# get training data\n",
    "cfg.eval.data.training = True\n",
    "# get validation data\n",
    "cfg.eval.data.validation = True\n",
    "# get testing data\n",
    "# Options for Brain are any subset of [1, 2, 3, 4, 5] or 'all' \n",
    "# Options for Heart are any subset of ['A', 'B', 'C', 'D'] or 'all'\n",
    "cfg.eval.data.testing = ['A']\n",
    "\n",
    "\n",
    "data = get_eval_data(\n",
    "    train_set=cfg.eval.data.training,\n",
    "    val_set=cfg.eval.data.validation,\n",
    "    test_sets=cfg.eval.data.testing,    \n",
    "    cfg=cfg,\n",
    "    subset_dict=subset_dict\n",
    ")\n",
    "\n",
    "print(f'\\nAvailable datasets are: {list(data.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc406aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sanity Check if config is as expected\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0331eb7",
   "metadata": {},
   "source": [
    "## General Eval Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda77dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####################################################\n",
    "### From eval.unet_test. Modify to fit your needs ###\n",
    "#####################################################\n",
    "\n",
    "from typing import Dict\n",
    "from omegaconf import OmegaConf\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import  epoch_average\n",
    "from losses import (\n",
    "    DiceScoreCalgary, \n",
    "    DiceScoreMMS\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def get_df_from_dict(\n",
    "    cfg: OmegaConf,\n",
    "    metrics: Dict\n",
    "):\n",
    "    # convert dict into seaborn-friendly pandas format\n",
    "    df = pd.DataFrame.from_dict(metrics).T\n",
    "    df['Domain'] = df.index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df = pd.melt(\n",
    "        df, \n",
    "        id_vars=['Domain'],\n",
    "        value_vars=df.columns.drop('Domain')\n",
    "    )\n",
    "    # add additional identifiers from config\n",
    "    df['Iteration'] = cfg.run.iteration\n",
    "    df['Model'] = cfg.unet[cfg.run.data_key].pre\n",
    "    df['Data'] = cfg.run.data_key\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def eval_set(\n",
    "    cfg: OmegaConf,\n",
    "    model: nn.Module,\n",
    "    dataset: Dataset\n",
    ") -> Dict:\n",
    "    if cfg.run.data_key == 'brain':\n",
    "        dataset.volume_wise = True\n",
    "        dataloader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=32,\n",
    "            shuffle=False,\n",
    "            drop_last=False\n",
    "        )\n",
    "        eval_metrics = {\n",
    "            'Volumetric Dice': DiceScoreCalgary(),\n",
    "            # Surface Dice is not defined for fragmented volumes, which we get\n",
    "            # by subsetting above. The original eval function in\n",
    "            # eval.unet_test does support surface Dice but not subsetting.\n",
    "            # 'Surface Dice': SurfaceDiceCalgary() \n",
    "        }\n",
    "        metrics = eval_brain_set(\n",
    "            model=model, \n",
    "            dataloader=dataloader, \n",
    "            eval_metrics=eval_metrics\n",
    "        )\n",
    "\n",
    "    elif cfg.run.data_key == 'heart':\n",
    "        dataloader = DataLoader(dataset, \n",
    "            batch_size=32, \n",
    "            shuffle=False, \n",
    "            drop_last=False\n",
    "        )\n",
    "        eval_metrics = {\n",
    "            \"Volumetric Dice\": DiceScoreMMS()\n",
    "        }\n",
    "        metrics = eval_heart_set(\n",
    "            model=model, \n",
    "            dataloader=dataloader, \n",
    "            eval_metrics=eval_metrics\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f'Invalid data key. No dataset named {cfg.run.data_key}'\n",
    "        )\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_brain_set(\n",
    "    model: nn.Module, \n",
    "    dataloader: DataLoader, \n",
    "    eval_metrics: Dict\n",
    ") -> Dict:\n",
    "    model.eval()\n",
    "    batch_sizes = []\n",
    "    epoch_metrics = {key: [] for key in eval_metrics.keys()}\n",
    "    for batch in dataloader:\n",
    "        input_ = batch['input']\n",
    "        target = batch['target']\n",
    "        batch_sizes.append(input_.shape[0])\n",
    "        net_out = model(input_.cuda()).detach().cpu()\n",
    "        for key, metric in eval_metrics.items():\n",
    "            epoch_metrics[key].append(metric(net_out,target).detach().mean().cpu())\n",
    "\n",
    "    for key, epoch_scores in epoch_metrics.items():\n",
    "        epoch_metrics[key] = epoch_average(epoch_scores, batch_sizes)\n",
    "\n",
    "    return epoch_metrics\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_heart_set(\n",
    "    model: nn.Module, \n",
    "    dataloader: DataLoader, \n",
    "    eval_metrics: Dict\n",
    ") -> Dict:\n",
    "    model.eval()\n",
    "    epoch_metrics = {key: [] for key in eval_metrics.keys()}\n",
    "    # saves batch sizes for each batch for averaging\n",
    "    batch_sizes = []\n",
    "    for batch in dataloader:\n",
    "        input_ = batch['input']\n",
    "        target = batch['target'].cuda()\n",
    "        # convert -1 labels to background\n",
    "        target[target == -1] = 0\n",
    "        # convert to one-hot encoding\n",
    "        target = F.one_hot(\n",
    "            target.long(), \n",
    "            num_classes=4\n",
    "        ).squeeze(1).permute(0,3,1,2)\n",
    "        # get model output\n",
    "        net_out = model(input_.cuda())\n",
    "        \n",
    "        batch_sizes.append(input_.shape[0])\n",
    "        for key, metric in eval_metrics.items():\n",
    "            epoch_metrics[key].append(\n",
    "                metric(net_out, target).detach().mean().cpu()\n",
    "            )\n",
    "            \n",
    "    for key, epoch_scores in epoch_metrics.items():\n",
    "        epoch_metrics[key] = epoch_average(epoch_scores, batch_sizes)\n",
    "        \n",
    "    return epoch_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037dc96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "\n",
    "for key in data.keys():\n",
    "    metrics[key] = eval_set(\n",
    "        cfg=cfg,\n",
    "        model=unet,\n",
    "        dataset=data[key]\n",
    "    )\n",
    "\n",
    "df = get_df_from_dict(cfg, metrics)\n",
    "\n",
    "sns.lineplot(\n",
    "    data=df, \n",
    "    x='Domain', \n",
    "    y='value', \n",
    "    hue='Model',\n",
    "    style='variable',\n",
    "    markers=True, \n",
    "    dashes=False, \n",
    "    markersize=10, \n",
    "    marker='x'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c591d",
   "metadata": {},
   "source": [
    "## Image selection and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad49482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select single image\n",
    "print(f'\\nAvailable datasets are:')\n",
    "for key in data:\n",
    "    print(f'  {key}: {len(data[key])} images')\n",
    "\n",
    "\n",
    "domain = 'val'\n",
    "idx    = 20\n",
    "image, seg_mask, voxel_spacing = data[domain][idx].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586974b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment image\n",
    "with torch.no_grad():\n",
    "    net_out = unet(image.unsqueeze(0).cuda()).detach().cpu()\n",
    "    if DATA_KEY == 'brain':\n",
    "        prediction = (net_out[0] > 0.5) * 1\n",
    "    elif DATA_KEY == 'heart':\n",
    "        prediction = net_out.argmax(1)\n",
    "    error_map = (seg_mask - prediction).abs()\n",
    "\n",
    "\n",
    "# plot results\n",
    "def plot_side_by_side(\n",
    "    images: List[Tensor], \n",
    "    titles: List[str] = None, \n",
    "    cmap: str = 'gray'\n",
    "):\n",
    "    n = len(images)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(n * 5, 5))\n",
    "    \n",
    "    if n == 1:  # If only one image, wrap axes in a list to make iterable\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(images[i], cmap=cmap)\n",
    "        ax.axis('off')\n",
    "        if titles:\n",
    "            ax.set_title(titles[i], fontsize=15)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "fig = plot_side_by_side(\n",
    "    images = [\n",
    "        image[0], \n",
    "        seg_mask[0], \n",
    "        prediction[0], \n",
    "        error_map[0],\n",
    "    ], \n",
    "    titles = [\n",
    "        'Input', \n",
    "        'Ground Truth', \n",
    "        'Prediction',\n",
    "        'Error Map',\n",
    "    ]  # comment to hide titles\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee57297",
   "metadata": {},
   "source": [
    "## Adapter Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f4426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple Adapter to store some inputs\n",
    "\n",
    "class DummyAdapter(nn.Module):\n",
    "    \"\"\"Dummy Adapter to store input means for a given layer per batch.\n",
    "\n",
    "    Attach this adapter via hooks (forward, preforward) to a layer in a \n",
    "    model by name of that layer. After each forward pass, the input means\n",
    "    are stored in the attribute `input_means` of this adapter.\n",
    "\n",
    "    Args:\n",
    "        swivel (str): Name of the layer in the model to attach to.\n",
    "        device (str, optional): Device to store the input means on. Defaults to 'cuda:0'.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        swivel: str,\n",
    "        device: str  = 'cuda:0'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # init args\n",
    "        self.swivel = swivel\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "\n",
    "\n",
    "    ### private methods ###\n",
    "        \n",
    "    def _aggregate(\n",
    "        self, \n",
    "        x: Tensor\n",
    "    ) -> Tensor:\n",
    "        \n",
    "        return x.mean(dim=(1,2,3))\n",
    "    \n",
    "\n",
    "    ### public methods ###\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        x: Tensor\n",
    "    ) -> Tensor:\n",
    "        self.input_means = self._aggregate(x).detach()\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "# A wrapper for this kind of adapter and the model itself\n",
    "    \n",
    "class DummyWrapper(nn.Module):\n",
    "    \"\"\"Wrapper for a model and a list of adapters.\n",
    "\n",
    "    Each adapter is attached to a layer in the model via hooks. The layers\n",
    "    are defined in the adapters themselves. \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        adapters: nn.ModuleList,\n",
    "        copy: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = deepcopy(model) if copy else model\n",
    "        self.adapters = adapters\n",
    "        self.adapter_handles = {}\n",
    "        self.model.eval()\n",
    "\n",
    "        self.input_means = {}\n",
    "\n",
    "\n",
    "    def hook_adapters(\n",
    "        self,\n",
    "    ) -> None:\n",
    "        # iterate over all adapters. You can use multiple simultaneously\n",
    "        for adapter in self.adapters:\n",
    "            # get the layer name of the layer we want to attach to\n",
    "            swivel = adapter.swivel\n",
    "            # get the actual layer from the model\n",
    "            layer  = self.model.get_submodule(swivel)\n",
    "            # get the hook function for this layer/adapter\n",
    "            hook = self._get_hook(adapter, swivel)\n",
    "            # attach the hook to the layer and save handle to remove hook \n",
    "            # if needed \n",
    "            self.adapter_handles[\n",
    "                swivel\n",
    "            ] = layer.register_forward_pre_hook(hook)\n",
    "\n",
    "\n",
    "    def _get_hook(\n",
    "        self,\n",
    "        adapter: nn.Module,\n",
    "        swivel: str\n",
    "    ) -> Callable:\n",
    "        # registering hooks requires a function that takes the module and the input,\n",
    "        # nothing more. To access the adapter anyways, we create the hook in a \n",
    "        # scope where the adapter is accessible, i.e. in another function.\n",
    "        def hook_fn(\n",
    "            module: nn.Module, \n",
    "            x: Tuple[Tensor]\n",
    "        ) -> Tensor:\n",
    "            # hook signature given by pytorch:\n",
    "            # hook(module, input) -> None or modified input\n",
    "\n",
    "            # pass through the adapter\n",
    "            out = adapter(x[0])\n",
    "            # save the results from this hook in a dict by layer name\n",
    "            self.input_means[swivel] = adapter.input_means.cpu()\n",
    "\n",
    "            return out\n",
    "        \n",
    "        return hook_fn\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        x: Tensor\n",
    "    ) -> Tensor:\n",
    "        # hijack the forward pass of your actual model\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfa0cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  run an example\n",
    "n = 3\n",
    "\n",
    "# select some layers at random\n",
    "layer_names = [layer[0] for layer in unet.named_modules() if 'conv' in layer[0]]\n",
    "selection = [\n",
    "    layer_names[i] for i in torch.randperm(len(layer_names))[:n]\n",
    "]\n",
    "\n",
    "# create adapters for these layers and wrap them in a wrapper\n",
    "adapters = nn.ModuleList(\n",
    "    [DummyAdapter(swivel) for swivel in selection]\n",
    ")\n",
    "\n",
    "wrapper = DummyWrapper(\n",
    "    model=unet, \n",
    "    adapters=adapters\n",
    ")\n",
    "wrapper.hook_adapters()\n",
    "\n",
    "# do a forward pass and inspect results\n",
    "input_batch = data[key][:5]['input']\n",
    "_ = wrapper(input_batch.cuda())\n",
    "\n",
    "print('Mean for batch / layer:')\n",
    "for layer in selection:\n",
    "    print(f'{wrapper.input_means[layer].tolist()} {layer}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
