{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcc42a44",
   "metadata": {},
   "source": [
    "## Basic config, package loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f308bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set CUDA device\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bc90b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import sys\n",
    "from omegaconf import OmegaConf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Callable, Tuple\n",
    "from copy import deepcopy\n",
    "import wandb\n",
    "\n",
    "sys.path.append('../')\n",
    "from data_utils import get_eval_data\n",
    "from model.unet import get_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7b240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load basic config\n",
    "cfg = OmegaConf.load('../configs/conf.yaml')\n",
    "OmegaConf.update(cfg, 'run.iteration', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417b74db",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c201726",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set dataset, either brain, heart or prostate\n",
    "DATA_KEY = 'prostate'\n",
    "OmegaConf.update(cfg, 'run.data_key', DATA_KEY)\n",
    "\n",
    "### get model\n",
    "# available models:\n",
    "#     - default-8\n",
    "#     - default-16\n",
    "#     - monai-8-4-4\n",
    "#     - monai-16-4-4\n",
    "#     - monai-16-4-8\n",
    "#     - monai-32-4-4\n",
    "#     - monai-64-4-4\n",
    "#     - swinunetr\n",
    "\n",
    "unet_name = 'monai-64-4-4'\n",
    "# unet_name = 'swinunetr'\n",
    "args = unet_name.split('-')\n",
    "cfg.unet[DATA_KEY].pre = unet_name\n",
    "cfg.unet[DATA_KEY].arch = args[0]\n",
    "cfg.unet[DATA_KEY].n_filters_init = None if unet_name == 'swinunetr' else int(args[1])\n",
    "if args[0] == 'monai':\n",
    "    cfg.unet[DATA_KEY].depth = int(args[2])\n",
    "    cfg.unet[DATA_KEY].num_res_units = int(args[3])\n",
    "\n",
    "# unet, state_dict = get_unet(\n",
    "#     cfg,\n",
    "#     update_cfg_with_swivels=False,\n",
    "#     return_state_dict=True)\n",
    "# unet.load_state_dict(state_dict)\n",
    "# _ = unet.cuda()\n",
    "\n",
    "wandb.init(\n",
    "    project=cfg.wandb.project,\n",
    "    config={\n",
    "        \"learning_rate\": cfg.unet[DATA_KEY].training.lr,\n",
    "        \"architecture\": unet_name,\n",
    "        \"dataset\": DATA_KEY\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405a0bcb",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad873a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import get_pmri_data_loaders\n",
    "from trainer.unet_trainer import get_unet_trainer\n",
    "\n",
    "unet = get_unet(cfg, update_cfg_with_swivels=False, return_state_dict=False)\n",
    "train_loader, val_loader = get_pmri_data_loaders(cfg=cfg)\n",
    "pmri_trainer = get_unet_trainer(cfg=cfg, train_loader=train_loader, val_loader=val_loader, model=unet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c095178",
   "metadata": {},
   "source": [
    "## Everything Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5255910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set debug mode for only a small fraction of the datasets. Speeds up this cell by alot\n",
    "cfg.debug = True\n",
    "\n",
    "\n",
    "# Wether and how you want to subset in case of Brain data. WARNING:\n",
    "# After subsetting the eval below will not work with surface\n",
    "# Dice anymore, because volumes are fragmented. \n",
    "APPLY_SUBSETTING = True\n",
    "OmegaConf.update(cfg, 'eval.data.subset.apply', APPLY_SUBSETTING)\n",
    "subset_params = {\n",
    "    'n_cases': 256,  # selects at most so many cases\n",
    "    'fraction': 0.1, # selects from the 10% worst cases w.r.t to a model\n",
    "}\n",
    "OmegaConf.update(\n",
    "    cfg, \n",
    "    'eval.data.subset.params', \n",
    "    OmegaConf.create(subset_params)\n",
    ")\n",
    "\n",
    "if cfg.eval.data.subset.apply:\n",
    "    subset_dict = OmegaConf.to_container(\n",
    "        cfg.eval.data.subset.params, \n",
    "        resolve=True, \n",
    "        throw_on_missing=True\n",
    "    )\n",
    "    subset_dict['unet'] = unet\n",
    "else:\n",
    "    subset_dict = None\n",
    "\n",
    "### select the datasets within the domain\n",
    "# get training data\n",
    "cfg.eval.data.training = True\n",
    "# get validation data\n",
    "cfg.eval.data.validation = True\n",
    "# get testing data\n",
    "# Options for Brain are any subset of [1, 2, 3, 4, 5] or 'all' \n",
    "# Options for Heart are any subset of ['A', 'B', 'C', 'D'] or 'all'\n",
    "cfg.eval.data.testing = ['A']\n",
    "\n",
    "\n",
    "data = get_eval_data(\n",
    "    train_set=cfg.eval.data.training,\n",
    "    val_set=cfg.eval.data.validation,\n",
    "    test_sets=cfg.eval.data.testing,    \n",
    "    cfg=cfg,\n",
    "    subset_dict=subset_dict\n",
    ")\n",
    "\n",
    "print(f'\\nAvailable datasets are: {list(data.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc406aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sanity Check if config is as expected\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0331eb7",
   "metadata": {},
   "source": [
    "## General Eval Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda77dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####################################################\n",
    "### From eval.unet_test. Modify to fit your needs ###\n",
    "#####################################################\n",
    "\n",
    "from typing import Dict\n",
    "from omegaconf import OmegaConf\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import  epoch_average\n",
    "from losses import (\n",
    "    DiceScoreCalgary, \n",
    "    DiceScoreMMS\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def get_df_from_dict(\n",
    "    cfg: OmegaConf,\n",
    "    metrics: Dict\n",
    "):\n",
    "    # convert dict into seaborn-friendly pandas format\n",
    "    df = pd.DataFrame.from_dict(metrics).T\n",
    "    df['Domain'] = df.index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df = pd.melt(\n",
    "        df, \n",
    "        id_vars=['Domain'],\n",
    "        value_vars=df.columns.drop('Domain')\n",
    "    )\n",
    "    # add additional identifiers from config\n",
    "    df['Iteration'] = cfg.run.iteration\n",
    "    df['Model'] = cfg.unet[cfg.run.data_key].pre\n",
    "    df['Data'] = cfg.run.data_key\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def eval_set(\n",
    "    cfg: OmegaConf,\n",
    "    model: nn.Module,\n",
    "    dataset: Dataset\n",
    ") -> Dict:\n",
    "    if cfg.run.data_key == 'brain':\n",
    "        dataset.volume_wise = True\n",
    "        dataloader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=32,\n",
    "            shuffle=False,\n",
    "            drop_last=False\n",
    "        )\n",
    "        eval_metrics = {\n",
    "            'Volumetric Dice': DiceScoreCalgary(),\n",
    "            # Surface Dice is not defined for fragmented volumes, which we get\n",
    "            # by subsetting above. The original eval function in\n",
    "            # eval.unet_test does support surface Dice but not subsetting.\n",
    "            # 'Surface Dice': SurfaceDiceCalgary() \n",
    "        }\n",
    "        metrics = eval_brain_set(\n",
    "            model=model, \n",
    "            dataloader=dataloader, \n",
    "            eval_metrics=eval_metrics\n",
    "        )\n",
    "\n",
    "    elif cfg.run.data_key == 'heart':\n",
    "        dataloader = DataLoader(dataset, \n",
    "            batch_size=32, \n",
    "            shuffle=False, \n",
    "            drop_last=False\n",
    "        )\n",
    "        eval_metrics = {\n",
    "            \"Volumetric Dice\": DiceScoreMMS()\n",
    "        }\n",
    "        metrics = eval_heart_set(\n",
    "            model=model, \n",
    "            dataloader=dataloader, \n",
    "            eval_metrics=eval_metrics\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f'Invalid data key. No dataset named {cfg.run.data_key}'\n",
    "        )\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_brain_set(\n",
    "    model: nn.Module, \n",
    "    dataloader: DataLoader, \n",
    "    eval_metrics: Dict\n",
    ") -> Dict:\n",
    "    model.eval()\n",
    "    batch_sizes = []\n",
    "    epoch_metrics = {key: [] for key in eval_metrics.keys()}\n",
    "    for batch in dataloader:\n",
    "        input_ = batch['input']\n",
    "        target = batch['target']\n",
    "        batch_sizes.append(input_.shape[0])\n",
    "        net_out = model(input_.cuda()).detach().cpu()\n",
    "        for key, metric in eval_metrics.items():\n",
    "            epoch_metrics[key].append(metric(net_out,target).detach().mean().cpu())\n",
    "\n",
    "    for key, epoch_scores in epoch_metrics.items():\n",
    "        epoch_metrics[key] = epoch_average(epoch_scores, batch_sizes)\n",
    "\n",
    "    return epoch_metrics\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_heart_set(\n",
    "    model: nn.Module, \n",
    "    dataloader: DataLoader, \n",
    "    eval_metrics: Dict\n",
    ") -> Dict:\n",
    "    model.eval()\n",
    "    epoch_metrics = {key: [] for key in eval_metrics.keys()}\n",
    "    # saves batch sizes for each batch for averaging\n",
    "    batch_sizes = []\n",
    "    for batch in dataloader:\n",
    "        input_ = batch['input']\n",
    "        target = batch['target'].cuda()\n",
    "        # convert -1 labels to background\n",
    "        target[target == -1] = 0\n",
    "        # convert to one-hot encoding\n",
    "        target = F.one_hot(\n",
    "            target.long(), \n",
    "            num_classes=4\n",
    "        ).squeeze(1).permute(0,3,1,2)\n",
    "        # get model output\n",
    "        net_out = model(input_.cuda())\n",
    "        \n",
    "        batch_sizes.append(input_.shape[0])\n",
    "        for key, metric in eval_metrics.items():\n",
    "            epoch_metrics[key].append(\n",
    "                metric(net_out, target).detach().mean().cpu()\n",
    "            )\n",
    "            \n",
    "    for key, epoch_scores in epoch_metrics.items():\n",
    "        epoch_metrics[key] = epoch_average(epoch_scores, batch_sizes)\n",
    "        \n",
    "    return epoch_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037dc96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "\n",
    "for key in data.keys():\n",
    "    metrics[key] = eval_set(\n",
    "        cfg=cfg,\n",
    "        model=unet,\n",
    "        dataset=data[key]\n",
    "    )\n",
    "\n",
    "df = get_df_from_dict(cfg, metrics)\n",
    "\n",
    "sns.lineplot(\n",
    "    data=df, \n",
    "    x='Domain', \n",
    "    y='value', \n",
    "    hue='Model',\n",
    "    style='variable',\n",
    "    markers=True, \n",
    "    dashes=False, \n",
    "    markersize=10, \n",
    "    marker='x'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c591d",
   "metadata": {},
   "source": [
    "## Image selection and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad49482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select single image\n",
    "print(f'\\nAvailable datasets are:')\n",
    "for key in data:\n",
    "    print(f'  {key}: {len(data[key])} images')\n",
    "\n",
    "\n",
    "domain = 'val'\n",
    "idx    = 20\n",
    "image, seg_mask, voxel_spacing = data[domain][idx].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586974b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment image\n",
    "with torch.no_grad():\n",
    "    net_out = unet(image.unsqueeze(0).cuda()).detach().cpu()\n",
    "    if DATA_KEY == 'brain':\n",
    "        prediction = (net_out[0] > 0.5) * 1\n",
    "    elif DATA_KEY == 'heart':\n",
    "        prediction = net_out.argmax(1)\n",
    "    error_map = (seg_mask - prediction).abs()\n",
    "\n",
    "\n",
    "# plot results\n",
    "def plot_side_by_side(\n",
    "    images: List[Tensor], \n",
    "    titles: List[str] = None, \n",
    "    cmap: str = 'gray'\n",
    "):\n",
    "    n = len(images)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(n * 5, 5))\n",
    "    \n",
    "    if n == 1:  # If only one image, wrap axes in a list to make iterable\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(images[i], cmap=cmap)\n",
    "        ax.axis('off')\n",
    "        if titles:\n",
    "            ax.set_title(titles[i], fontsize=15)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "fig = plot_side_by_side(\n",
    "    images = [\n",
    "        image[0], \n",
    "        seg_mask[0], \n",
    "        prediction[0], \n",
    "        error_map[0],\n",
    "    ], \n",
    "    titles = [\n",
    "        'Input', \n",
    "        'Ground Truth', \n",
    "        'Prediction',\n",
    "        'Error Map',\n",
    "    ]  # comment to hide titles\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee57297",
   "metadata": {},
   "source": [
    "## Adapter Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f4426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple Adapter to store some inputs\n",
    "\n",
    "class DummyAdapter(nn.Module):\n",
    "    \"\"\"Dummy Adapter to store input means for a given layer per batch.\n",
    "\n",
    "    Attach this adapter via hooks (forward, preforward) to a layer in a \n",
    "    model by name of that layer. After each forward pass, the input means\n",
    "    are stored in the attribute `input_means` of this adapter.\n",
    "\n",
    "    Args:\n",
    "        swivel (str): Name of the layer in the model to attach to.\n",
    "        device (str, optional): Device to store the input means on. Defaults to 'cuda:0'.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        swivel: str,\n",
    "        device: str  = 'cuda:0'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # init args\n",
    "        self.swivel = swivel\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "\n",
    "\n",
    "    ### private methods ###\n",
    "        \n",
    "    def _aggregate(\n",
    "        self, \n",
    "        x: Tensor\n",
    "    ) -> Tensor:\n",
    "        \n",
    "        return x.mean(dim=(1,2,3))\n",
    "    \n",
    "\n",
    "    ### public methods ###\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        x: Tensor\n",
    "    ) -> Tensor:\n",
    "        self.input_means = self._aggregate(x).detach()\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "# A wrapper for this kind of adapter and the model itself\n",
    "    \n",
    "class DummyWrapper(nn.Module):\n",
    "    \"\"\"Wrapper for a model and a list of adapters.\n",
    "\n",
    "    Each adapter is attached to a layer in the model via hooks. The layers\n",
    "    are defined in the adapters themselves. \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        adapters: nn.ModuleList,\n",
    "        copy: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = deepcopy(model) if copy else model\n",
    "        self.adapters = adapters\n",
    "        self.adapter_handles = {}\n",
    "        self.model.eval()\n",
    "\n",
    "        self.input_means = {}\n",
    "\n",
    "\n",
    "    def hook_adapters(\n",
    "        self,\n",
    "    ) -> None:\n",
    "        # iterate over all adapters. You can use multiple simultaneously\n",
    "        for adapter in self.adapters:\n",
    "            # get the layer name of the layer we want to attach to\n",
    "            swivel = adapter.swivel\n",
    "            # get the actual layer from the model\n",
    "            layer  = self.model.get_submodule(swivel)\n",
    "            # get the hook function for this layer/adapter\n",
    "            hook = self._get_hook(adapter, swivel)\n",
    "            # attach the hook to the layer and save handle to remove hook \n",
    "            # if needed \n",
    "            self.adapter_handles[\n",
    "                swivel\n",
    "            ] = layer.register_forward_pre_hook(hook)\n",
    "\n",
    "\n",
    "    def _get_hook(\n",
    "        self,\n",
    "        adapter: nn.Module,\n",
    "        swivel: str\n",
    "    ) -> Callable:\n",
    "        # registering hooks requires a function that takes the module and the input,\n",
    "        # nothing more. To access the adapter anyways, we create the hook in a \n",
    "        # scope where the adapter is accessible, i.e. in another function.\n",
    "        def hook_fn(\n",
    "            module: nn.Module, \n",
    "            x: Tuple[Tensor]\n",
    "        ) -> Tensor:\n",
    "            # hook signature given by pytorch:\n",
    "            # hook(module, input) -> None or modified input\n",
    "\n",
    "            # pass through the adapter\n",
    "            out = adapter(x[0])\n",
    "            # save the results from this hook in a dict by layer name\n",
    "            self.input_means[swivel] = adapter.input_means.cpu()\n",
    "\n",
    "            return out\n",
    "        \n",
    "        return hook_fn\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        x: Tensor\n",
    "    ) -> Tensor:\n",
    "        # hijack the forward pass of your actual model\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfa0cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  run an example\n",
    "n = 3\n",
    "\n",
    "# select some layers at random\n",
    "layer_names = [layer[0] for layer in unet.named_modules() if 'conv' in layer[0]]\n",
    "selection = [\n",
    "    layer_names[i] for i in torch.randperm(len(layer_names))[:n]\n",
    "]\n",
    "\n",
    "# create adapters for these layers and wrap them in a wrapper\n",
    "adapters = nn.ModuleList(\n",
    "    [DummyAdapter(swivel) for swivel in selection]\n",
    ")\n",
    "\n",
    "wrapper = DummyWrapper(\n",
    "    model=unet, \n",
    "    adapters=adapters\n",
    ")\n",
    "wrapper.hook_adapters()\n",
    "\n",
    "# do a forward pass and inspect results\n",
    "input_batch = data[key][:5]['input']\n",
    "_ = wrapper(input_batch.cuda())\n",
    "\n",
    "print('Mean for batch / layer:')\n",
    "for layer in selection:\n",
    "    print(f'{wrapper.input_means[layer].tolist()} {layer}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
